# Cline Project Rules and Preferences

## Project Intelligence

### Development Workflow
- Always update the progress.md file after completing significant milestones
- Review and update activeContext.md at the beginning of each session
- Follow the project structure defined in the PRD strictly

### Code Patterns
- All Python code should follow PEP 8 style guide
- Terraform code should use clear variable names and include comments
- SQL in dbt models should be consistently formatted and documented

### File Organization
- Keep all Terraform files in the terraform/ directory
- Airflow DAGs should be in the airflow/dags/ directory
- dbt models should be separated into staging/ and curated/ subdirectories

### Naming Conventions
- Use snake_case for Python variables, functions, and file names
- Use camelCase for Terraform resource names
- Prefix staging dbt models with "stg_"
- Prefix curated dbt models with appropriate domain names

### Documentation Standards
- Include detailed comments in code explaining "why" not just "what"
- Keep README.md updated with setup instructions and architecture overview
- Document all environment variables and configuration requirements

## Implementation Patterns

### GCP Resources
- All resource names should include the project name as a prefix
- Use appropriate resource tags for cost tracking
- Configure appropriate retention policies for logs and data

### Airflow DAGs
- Use meaningful task IDs that describe the operation
- Implement proper error handling and retries
- Use XCom sparingly and for small data only

### dbt Models
- Include documentation for all models and columns
- Implement tests for referential integrity and data quality
- Use appropriate materializations based on data volume and query patterns

### Data Quality
- Validate data types during loading to BigQuery
- Check for null values in required fields
- Implement row count validation between pipeline stages

## Project-Specific Guidelines

### AIS Data Handling
- Consider time zone handling for timestamp fields
- Be aware of potential duplicate MMSI values
- Implement data quality checks for geographic coordinates

### Performance Optimization
- Partition BigQuery tables by timestamp for efficient querying
- Consider clustering by frequently filtered columns (e.g., MMSI, ship type)
- Monitor query costs and optimize as needed

### Deployment
- Use separate GCP projects for development and production
- Implement proper state management for Terraform
- Consider CI/CD pipeline for automated testing and deployment

This document will evolve as we learn more about the project and discover additional patterns and preferences. It serves as a guide for maintaining consistency and quality throughout development.
